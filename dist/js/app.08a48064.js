(function(){"use strict";var o={319:function(o,r,s){var a=s(963),e=s(252);const c={id:"root"},i={class:"first-row"},l={class:"second-row"};function n(o,r,s,a,n,d){const t=(0,e.up)("gtx1080"),m=(0,e.up)("gtx1070ti"),v=(0,e.up)("rtx2080"),p=(0,e.up)("gtx1060"),u=(0,e.up)("gtx1050"),g=(0,e.up)("gtx770"),b=(0,e.up)("gtx750"),G=(0,e.up)("rtx3090"),h=(0,e.up)("rtx3060"),w=(0,e.up)("gtx970");return(0,e.wg)(),(0,e.iD)("div",c,[(0,e._)("div",i,[(0,e.Wm)(t),(0,e.Wm)(m),(0,e.Wm)(v),(0,e.Wm)(p),(0,e.Wm)(u)]),(0,e._)("div",l,[(0,e.Wm)(g),(0,e.Wm)(b),(0,e.Wm)(G),(0,e.Wm)(h),(0,e.Wm)(w)])])}var d=s.p+"img/1080.5319eafe.png";const t={class:"root"},m=(0,e.uE)('<img class="card-image1080" src="'+d+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 1080</h1><p class="card-text"> GeForce GTX 1080 — высокопроизводительная видеокарта от NVIDIA, выпущенная 27 мая 2016 года. </p>',4),v=[m];function p(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",t,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show1080Modal=!0)},v),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show1080Modal,onClose:r[1]||(r[1]=r=>o.show1080Modal=!1)},null,8,["show"])]))])}var u=s.p+"img/back.3c2015cf.svg",g=s.p+"img/nvidia.27b0746c.png";const b={key:0,id:"modal-container"},G={class:"controls"},h=(0,e._)("img",{src:u},null,-1),w=[h],D=(0,e._)("img",{src:g,class:"nvidia"},null,-1),I=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 1080 — это высокопроизводительная видеокарта от NVIDIA, выпущенная 27 мая 2016 года.<br><br> Созданная по 16-нм техпроцессу и основанная на графическом процессоре GP104, в варианте GP104-400-A1 карта поддерживает DirectX 12. Это гарантирует, что все современные игры будут работать на GeForce GTX 1080.<br><br> Графический процессор GP104 представляет собой большой чип с площадью кристалла 314 мм² и 7 200 миллионами транзисторов. Он имеет 2560 блоков затенения, 160 блоков наложения текстур и 64 ROP. NVIDIA объединила 8 ГБ памяти GDDR5X с GeForce GTX 1080, которые подключаются с помощью 256-битного интерфейса памяти. <br><br>Графический процессор работает на частоте 1607 МГц, которую можно увеличить до 1733 МГц, память работает на частоте 1251 МГц (10 Гбит/с эффективно). Будучи двухслотовой картой, NVIDIA GeForce GTX 1080 получает питание от 1x 8-контактного разъема питания с максимальной потребляемой мощностью 180 Вт.<br><br> Выходы дисплея включают: 1x DVI, 1x HDMI 2.0, 3x DisplayPort 1.4a. GeForce GTX 1080 подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16. Размеры карты составляют 267 мм x 112 мм x 40 мм, и она имеет двухслотовое решение для охлаждения.<br><br> Его цена на старте составляла 2021,91 беларусских рублей. </p></div><div class="card-image1080gtx"><img src="'+d+'" alt=""></div></div>',1);function x(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",b,[(0,e._)("div",G,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},w),D]),I])):(0,e.kq)("",!0)}var T={props:{show:Boolean}},X=s(744);const M=(0,X.Z)(T,[["render",x]]);var _=M,F={components:{Modal:_},data:()=>({show1080Modal:!1})};const y=(0,X.Z)(F,[["render",p]]);var f=y,A=s.p+"img/1070ti.1ecd79ae.png";const R={class:"root"},k=(0,e.uE)('<img class="card-image1070" src="'+A+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 1070ti</h1><p class="card-text"> GeForce GTX 1070 Ti — высокопроизводительная видеокарта от NVIDIA, выпущенная 2 ноября 2017 года. </p>',4),V=[k];function N(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",R,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show1070Modal=!0)},V),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show1070Modal,onClose:r[1]||(r[1]=r=>o.show1070Modal=!1)},null,8,["show"])]))])}const P={key:0,id:"modal-container"},C={class:"controls"},E=(0,e._)("img",{src:u},null,-1),Z=[E],O=(0,e._)("img",{src:g,class:"nvidia"},null,-1),W=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 1070 Ti — это высокопроизводительная видеокарта от NVIDIA, выпущенная 2 ноября 2017 года. <br><br>Созданная на основе 16-нм техпроцесса и основанная на графическом процессоре GP104, в варианте GP104-300-A1 карта поддерживает DirectX. 12. Это гарантирует, что все современные игры будут работать на GeForce GTX 1070 Ti. <br><br>Графический процессор GP104 представляет собой большой чип с площадью кристалла 314 мм² и 7 200 миллионами транзисторов. В отличие от полностью разблокированной GeForce GTX 1080, которая использует тот же графический процессор, но поддерживает все 2560 шейдеров, NVIDIA отключила некоторые блоки обработки теней на GeForce GTX 1070 Ti, чтобы достичь целевого количества шейдеров продукта. Он имеет 2432 модуля затенения, 152 модуля наложения текстур и 64 ROP.<br><br> NVIDIA объединила 8 ГБ памяти GDDR5 с GeForce GTX 1070 Ti, которые подключаются с помощью 256-битного интерфейса памяти. Графический процессор работает на частоте 1607 МГц, которую можно увеличить до 1683 МГц, память работает на частоте 2002 МГц (эффективно 8 Гбит/с).<br><br> Будучи двухслотовой картой, NVIDIA GeForce GTX 1070 Ti получает питание от 1x 8-контактного разъема питания с максимальной потребляемой мощностью 180 Вт.<br><br> Выходы дисплея включают: 1x DVI, 1x HDMI 2.0, 3x DisplayPort 1.4a. GeForce GTX 1070 Ti подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16. Размеры карты составляют 267 мм x 112 мм x 40 мм, и она имеет двухслотовое решение для охлаждения.<br><br> Его цена на старте составляла 1346,82 беларусских рублей. </p></div><div class="card-image1070ti"><img src="'+A+'"></div></div>',1);function j(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",P,[(0,e._)("div",C,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},Z),O]),W])):(0,e.kq)("",!0)}var H={props:{show:Boolean}};const q=(0,X.Z)(H,[["render",j]]);var B=q,$={components:{Modal:B},data:()=>({show1070Modal:!1})};const U=(0,X.Z)($,[["render",N]]);var K=U,S=s.p+"img/2080.2aede4aa.png";const z={class:"root"},J=(0,e.uE)('<img class="card-image2080" src="'+S+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">RTX 2080</h1><p class="card-text"> GeForce RTX 2080 — это видеокарта для энтузиастов от NVIDIA, выпущенная 20 сентября 2018 года. </p>',4),L=[J];function Q(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",z,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show2080Modal=!0)},L),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show2080Modal,onClose:r[1]||(r[1]=r=>o.show2080Modal=!1)},null,8,["show"])]))])}const Y={key:0,id:"modal-container"},oo={class:"controls"},ro=(0,e._)("img",{src:u},null,-1),so=[ro],ao=(0,e._)("img",{src:g,class:"nvidia"},null,-1),eo=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce RTX 2080 — это видеокарта NVIDIA для энтузиастов, выпущенная 20 сентября 2018 года.<br><br> Созданная на основе 12-нм техпроцесса и основанная на графическом процессоре TU104, в варианте TU104-400A-A1 карта поддерживает DirectX 12. Окончательный. Это гарантирует, что все современные игры будут работать на GeForce RTX 2080.<br><br> Кроме того, возможность DirectX 12 Ultimate гарантирует поддержку аппаратной трассировки лучей, шейдинга с переменной скоростью и многого другого в будущих видеоиграх. Графический процессор TU104 представляет собой большой чип с площадью кристалла 545 мм² и 13 600 млн транзисторов.<br><br> В отличие от полностью разблокированной GeForce RTX 2080 SUPER, которая использует тот же графический процессор, но поддерживает все 3072 шейдера, NVIDIA отключила некоторые блоки затенения на GeForce RTX 2080, чтобы достичь целевого количества шейдеров продукта. Он имеет 2944 модуля затенения, 184 модуля наложения текстур и 64 ROP.<br><br> Также включены 368 тензорных ядер, которые помогают повысить скорость приложений машинного обучения. Карта также имеет 46 ядер ускорения трассировки лучей. NVIDIA объединила 8 ГБ памяти GDDR6 с GeForce RTX 2080, которые подключаются с помощью 256-битного интерфейса памяти. Графический процессор работает на частоте 1515 МГц, которую можно увеличить до 1710 МГц, память работает на частоте 1750 МГц (14 Гбит/с эффективно).<br><br> Будучи двухслотовой картой, NVIDIA GeForce RTX 2080 получает питание от 1x 6-контактного + 1x 8-контактного разъема питания с максимальной потребляемой мощностью 215 Вт. Выходы дисплея включают: 1x HDMI 2.0, 3x DisplayPort 1.4a, 1x USB Type-C. GeForce RTX 2080 подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16. Размеры карты составляют 267 мм x 116 мм x 35 мм, и она имеет двухслотовое решение для охлаждения.<br><br> Его цена на старте составляла 2359,46 беларусских рублей. </p></div><div class="card-image2080RTX"><img src="'+S+'" alt=""></div></div>',1);function co(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",Y,[(0,e._)("div",oo,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},so),ao]),eo])):(0,e.kq)("",!0)}var io={props:{show:Boolean}};const lo=(0,X.Z)(io,[["render",co]]);var no=lo,to={components:{Modal:no},data:()=>({show2080Modal:!1})};const mo=(0,X.Z)(to,[["render",Q]]);var vo=mo,po=s.p+"img/1060.b43a0d94.png";const uo={class:"root"},go=(0,e.uE)('<img class="card-image1060" src="'+po+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 1060</h1><p class="card-text"> GeForce GTX 1060 6 ГБ — видеокарта высокопроизводительного сегмента от NVIDIA, выпущенная 19 июля 2016 года. </p>',4),bo=[go];function Go(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",uo,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show1060Modal=!0)},bo),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show1060Modal,onClose:r[1]||(r[1]=r=>o.show1060Modal=!1)},null,8,["show"])]))])}const ho={key:0,id:"modal-container"},wo={class:"controls"},Do=(0,e._)("img",{src:u},null,-1),Io=[Do],xo=(0,e._)("img",{src:g,class:"nvidia"},null,-1),To=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 1060 6 ГБ — это видеокарта высокопроизводительного сегмента от NVIDIA, выпущенная 19 июля 2016 года. <br><br>Созданная на основе 16-нм техпроцесса и основанная на графическом процессоре GP106, в варианте GP106-400-A1 карта поддерживает DirectX 12. Это гарантирует, что все современные игры будут работать на GeForce GTX 1060 6 ГБ. Графический процессор GP106 представляет собой чип среднего размера с площадью кристалла 200 мм² и 4 400 миллионами транзисторов. <br><br>Он имеет 1280 блоков затенения, 80 блоков наложения текстур и 48 ROP. NVIDIA объединила 6 ГБ памяти GDDR5 с GeForce GTX 1060 6 ГБ, которые подключаются с помощью 192-битного интерфейса памяти.<br><br> Графический процессор работает на частоте 1506 МГц, которую можно увеличить до 1709 МГц, память работает на частоте 2002 МГц (эффективно 8 Гбит/с). Будучи двухслотовой картой, NVIDIA GeForce GTX 1060 6 ГБ получает питание от 1x 6-контактного разъема питания с максимальной потребляемой мощностью 120 Вт. Выходы дисплея включают: 1x DVI, 1x HDMI 2.0, 3x DisplayPort 1.4a.<br><br> GeForce GTX 1060 6 ГБ подключается к остальной системе по интерфейсу PCI-Express 3.0 x16. Карта имеет длину 250 мм, ширину 111 мм и имеет двухслотовое решение для охлаждения.<br><br> Его цена на старте составляла 1009,27 беларусских рублей. </p></div><div class="card-image1060gtx"><img src="'+po+'" alt=""></div></div>',1);function Xo(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",ho,[(0,e._)("div",wo,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},Io),xo]),To])):(0,e.kq)("",!0)}var Mo={props:{show:Boolean}};const _o=(0,X.Z)(Mo,[["render",Xo]]);var Fo=_o,yo={components:{Modal:Fo},data:()=>({show1060Modal:!1})};const fo=(0,X.Z)(yo,[["render",Go]]);var Ao=fo,Ro=s.p+"img/1050.4682b8f5.png";const ko={class:"root"},Vo=(0,e.uE)('<img class="card-image1050" src="'+Ro+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 1050</h1><p class="card-text"> GeForce GTX 1050 — видеокарта среднего класса от NVIDIA, выпущенная 25 октября 2016 года. </p>',4),No=[Vo];function Po(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",ko,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show1050Modal=!0)},No),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show1050Modal,onClose:r[1]||(r[1]=r=>o.show1050Modal=!1)},null,8,["show"])]))])}const Co={key:0,id:"modal-container"},Eo={class:"controls"},Zo=(0,e._)("img",{src:u},null,-1),Oo=[Zo],Wo=(0,e._)("img",{src:g,class:"nvidia"},null,-1),jo=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 1050 — это видеокарта среднего класса от NVIDIA, выпущенная 25 октября 2016 года.<br><br> Созданная на основе 14-нм техпроцесса и основанная на графическом процессоре GP107, в варианте GP107-300-A1 карта поддерживает DirectX 12. Это гарантирует, что все современные игры будут работать на GeForce GTX 1050. <br><br>Графический процессор GP107 представляет собой чип среднего размера с площадью кристалла 132 мм² и 3 300 миллионами транзисторов. В отличие от полностью разблокированной GeForce GTX 1050 Ti, которая использует тот же графический процессор, но поддерживает все 768 шейдеров, NVIDIA отключила некоторые шейдерные блоки на GeForce GTX 1050, чтобы достичь целевого количества шейдеров продукта. Он имеет 640 блоков затенения, 40 блоков наложения текстур и 32 ROP.<br><br> NVIDIA объединила 2048 МБ памяти GDDR5 с GeForce GTX 1050, которые подключаются через 128-битный интерфейс памяти. Графический процессор работает на частоте 1354 МГц, которая может быть увеличена до 1455 МГц, память работает на частоте 1752 МГц (эффективно 7 Гбит/с). Будучи двухслотовой картой, NVIDIA GeForce GTX 1050 не требует дополнительного разъема питания, ее потребляемая мощность составляет максимум 75 Вт. <br><br>Выходы дисплея включают: 1x DVI, 1x HDMI 2.0, 1x DisplayPort 1.4a. GeForce GTX 1050 подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16. Карта имеет длину 145 мм, ширину 111 мм и имеет двухслотовое решение для охлаждения.<br><br> Его цена на момент запуска составляла 367,93 беларусских рублей. </p></div><div class="card-image1050gtx"><img src="'+Ro+'" alt=""></div></div>',1);function Ho(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",Co,[(0,e._)("div",Eo,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},Oo),Wo]),jo])):(0,e.kq)("",!0)}var qo={props:{show:Boolean}};const Bo=(0,X.Z)(qo,[["render",Ho]]);var $o=Bo,Uo={components:{Modal:$o},data:()=>({show1050Modal:!1})};const Ko=(0,X.Z)(Uo,[["render",Po]]);var So=Ko,zo=s.p+"img/770.5fee0f44.png";const Jo={class:"root"},Lo=(0,e.uE)('<img class="card-image770" src="'+zo+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 770</h1><p class="card-text"> GeForce GTX 770 — это высокопроизводительная видеокарта от NVIDIA, выпущенная 30 мая 2013 года. </p>',4),Qo=[Lo];function Yo(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",Jo,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show770Modal=!0)},Qo),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show770Modal,onClose:r[1]||(r[1]=r=>o.show770Modal=!1)},null,8,["show"])]))])}const or={key:0,id:"modal-container"},rr={class:"controls"},sr=(0,e._)("img",{src:u},null,-1),ar=[sr],er=(0,e._)("img",{src:g,class:"nvidia"},null,-1),cr=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 770 — это высококлассная видеокарта от NVIDIA, выпущенная 30 мая 2013 года.<br><br> Созданная по 28-нм техпроцессу и основанная на графическом процессоре GK104, в варианте GK104-425-A2 карта поддерживает DirectX 12.<br><br> Графический процессор GK104 представляет собой чип среднего размера с площадью кристалла 294 мм² и 3 540 миллионами транзисторов. <br><br> Он имеет 1536 блоков затенения, 128 блоков наложения текстур и 32 ROP. NVIDIA объединила 2048 МБ памяти GDDR5 с GeForce GTX 770, которые подключаются с помощью 256-битного интерфейса памяти. Графический процессор работает на частоте 1046 МГц, которую можно увеличить до 1085 МГц, память работает на частоте 1753 МГц (эффективно 7 Гбит/с).<br><br> Будучи двухслотовой картой, NVIDIA GeForce GTX 770 получает питание от 1x 6-контактного + 1x 8-контактного разъема питания с максимальной потребляемой мощностью 230 Вт. Выходы дисплея включают: 2x DVI, 1x HDMI 1.4a, 1x DisplayPort 1.2. GeForce GTX 770 подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16.<br><br> Размеры карты составляют 267 мм x 111 мм x 38 мм, и она имеет двухслотовое решение для охлаждения.<br><br> Его цена на старте составляла 1346,82 беларусских рублей. </p></div><div class="card-image770gtx"><img src="'+zo+'" alt=""></div></div>',1);function ir(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",or,[(0,e._)("div",rr,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},ar),er]),cr])):(0,e.kq)("",!0)}var lr=s(262),nr=s(38),dr={props:{show:Boolean},setup(o){const r=(0,lr.iH)(0),s=(0,lr.qj)({number:0});(0,lr.iH)(o.show);return nr.ZP.to(s,{duration:.5,number:Number(550)||0}),(0,e.bv)((()=>{console.log(o.show)})),{number:r,tweened:s}}};const tr=(0,X.Z)(dr,[["render",ir]]);var mr=tr,vr={components:{Modal:mr},data:()=>({show770Modal:!1})};const pr=(0,X.Z)(vr,[["render",Yo]]);var ur=pr,gr=s.p+"img/750.ed5b8d12.png";const br={class:"root"},Gr=(0,e.uE)('<img class="card-image750" src="'+gr+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 750</h1><p class="card-text"> GeForce GTX 750 — видеокарта среднего класса от NVIDIA, выпущенная 18 февраля 2014 года. </p>',4),hr=[Gr];function wr(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",br,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show750Modal=!0)},hr),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show750Modal,onClose:r[1]||(r[1]=r=>o.show750Modal=!1)},null,8,["show"])]))])}const Dr={key:0,id:"modal-container"},Ir={class:"controls"},xr=(0,e._)("img",{src:u},null,-1),Tr=[xr],Xr=(0,e._)("img",{src:g,class:"nvidia"},null,-1),Mr=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 750 — это видеокарта среднего класса от NVIDIA, выпущенная 18 февраля 2014 года.<br><br>Созданная по 28-нм техпроцессу и основанная на графическом процессоре GM107, в варианте GM107-300-A2 карта поддерживает DirectX 12. <br><br>Графический процессор GM107 представляет собой чип среднего размера с площадью кристалла 148 мм² и 1 870 миллионами транзисторов. В отличие от полностью разблокированной GeForce GTX 750 Ti, которая использует тот же графический процессор, но поддерживает все 640 шейдеров, NVIDIA отключила некоторые шейдерные блоки на GeForce GTX 750, чтобы достичь целевого количества шейдеров продукта. Он имеет 512 блоков затенения, 32 блока наложения текстур и 16 ROP.<br><br> NVIDIA объединила 1024 МБ памяти GDDR5 с GeForce GTX 750, которые подключаются через 128-битный интерфейс памяти.<br><br> Графический процессор работает на частоте 1020 МГц, которую можно увеличить до 1085 МГц, память работает на частоте 1253 МГц (эффективно 5 Гбит/с). Будучи однослотовой картой, NVIDIA GeForce GTX 750 не требует дополнительного разъема питания, ее потребляемая мощность составляет максимум 55 Вт. <br><br>Выходы дисплея включают: 2x DVI, 1x mini-HDMI 2.0. GeForce GTX 750 подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16. Карта имеет длину 145 мм и имеет однослотовое решение для охлаждения.<br><br> Его цена на момент запуска составляла 671,72 беларусских рублей. </p></div><div class="card-image750gtx"><img src="'+gr+'" alt=""></div></div>',1);function _r(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",Dr,[(0,e._)("div",Ir,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},Tr),Xr]),Mr])):(0,e.kq)("",!0)}var Fr={props:{show:Boolean},setup(o){const r=(0,lr.iH)(0),s=(0,lr.qj)({number:0});(0,lr.iH)(o.show);return nr.ZP.to(s,{duration:.5,number:Number(550)||0}),(0,e.bv)((()=>{console.log(o.show)})),{number:r,tweened:s}}};const yr=(0,X.Z)(Fr,[["render",_r]]);var fr=yr,Ar={components:{Modal:fr},data:()=>({show750Modal:!1})};const Rr=(0,X.Z)(Ar,[["render",wr]]);var kr=Rr,Vr=s.p+"img/3090.b25493be.png";const Nr={class:"root"},Pr=(0,e.uE)('<img class="card-image3090" src="'+Vr+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">RTX 3090</h1><p class="card-text"> GeForce RTX 3090 — это видеокарта для энтузиастов от NVIDIA, выпущенная 1 сентября 2020 года. </p>',4),Cr=[Pr];function Er(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",Nr,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show3090Modal=!0)},Cr),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show3090Modal,onClose:r[1]||(r[1]=r=>o.show3090Modal=!1)},null,8,["show"])]))])}const Zr={key:0,id:"modal-container"},Or={class:"controls"},Wr=(0,e._)("img",{src:u},null,-1),jr=[Wr],Hr=(0,e._)("img",{src:g,class:"nvidia"},null,-1),qr=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce RTX 3090 — это видеокарта NVIDIA для энтузиастов, выпущенная 1 сентября 2020 года.<br><br> Созданная на основе 8-нм техпроцесса и основанная на графическом процессоре GA102, в варианте GA102-300-A1 карта поддерживает DirectX 12. Окончательный. Это гарантирует, что все современные игры будут работать на GeForce RTX 3090. Кроме того, возможность DirectX 12 Ultimate гарантирует поддержку аппаратной трассировки лучей, шейдинга с переменной скоростью и многого другого в будущих видеоиграх.<br><br> Графический процессор GA102 представляет собой большой чип с площадью кристалла 628 мм² и 28 300 миллионами транзисторов. В отличие от полностью разблокированной GeForce RTX 3090 Ti, которая использует тот же графический процессор, но поддерживает все 10752 шейдера, NVIDIA отключила некоторые блоки затенения на GeForce RTX 3090, чтобы достичь целевого количества шейдеров продукта. Он имеет 10496 блоков затенения, 328 блоков наложения текстур и 112 ROP. Также включены 328 тензорных ядер, которые помогают повысить скорость приложений машинного обучения.<br><br> Карта также имеет 82 ядра ускорения трассировки лучей. NVIDIA объединила 24 ГБ памяти GDDR6X с GeForce RTX 3090, которые подключаются с помощью 384-битного интерфейса памяти. Графический процессор работает на частоте 1395 МГц, которая может быть увеличена до 1695 МГц, память работает на частоте 1219 МГц (эффективная 19,5 Гбит/с).<br><br> Будучи картой с тремя слотами, NVIDIA GeForce RTX 3090 получает питание от 1x 12-контактного разъема питания с максимальной потребляемой мощностью 350 Вт. Выходы дисплея включают: 1x HDMI 2.1, 3x DisplayPort 1.4a. GeForce RTX 3090 подключается к остальной системе с помощью интерфейса PCI-Express 4.0 x16. Размеры карты составляют 336 мм x 140 мм x 61 мм, и она оснащена системой охлаждения с тремя слотами.<br><br> Его цена на момент запуска составляла 7754 Беларуских рублей. </p></div><div class="card-image3090RTX"><img src="'+Vr+'" alt=""></div></div>',1);function Br(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",Zr,[(0,e._)("div",Or,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},jr),Hr]),qr])):(0,e.kq)("",!0)}var $r={props:{show:Boolean}};const Ur=(0,X.Z)($r,[["render",Br]]);var Kr=Ur,Sr={components:{Modal:Kr},data:()=>({show3090Modal:!1})};const zr=(0,X.Z)(Sr,[["render",Er]]);var Jr=zr,Lr=s.p+"img/3060.1aa0be2b.png";const Qr={class:"root"},Yr=(0,e.uE)('<img class="card-image3060" src="'+Lr+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">RTX 3060</h1><p class="card-text"> GeForce RTX 3060 — это видеокарта высокопроизводительного сегмента от NVIDIA, выпущенная 12 января 2021 года. </p>',4),os=[Yr];function rs(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",Qr,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show3060Modal=!0)},os),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show3060Modal,onClose:r[1]||(r[1]=r=>o.show3060Modal=!1)},null,8,["show"])]))])}const ss={key:0,id:"modal-container"},as={class:"controls"},es=(0,e._)("img",{src:u},null,-1),cs=[es],is=(0,e._)("img",{src:g,class:"nvidia"},null,-1),ls=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce RTX 3060 — это видеокарта высокопроизводительного сегмента от NVIDIA, выпущенная 12 января 2021 года.<br><br> Созданная на основе 8-нм техпроцесса и основанная на графическом процессоре GA106, в варианте GA106-300-A1 карта поддерживает DirectX 12.<br><br> Окончательный. Это гарантирует, что все современные игры будут работать на GeForce RTX 3060. Кроме того, возможность DirectX 12 Ultimate гарантирует поддержку аппаратной трассировки лучей, шейдинга с переменной скоростью и многого другого в будущих видеоиграх. Графический процессор GA106 представляет собой чип среднего размера с площадью кристалла 276 мм² и 12 000 миллионов транзисторов.<br><br> Он имеет 3584 блока затенения, 112 блоков наложения текстур и 48 ROP. Также включены 112 тензорных ядер, которые помогают повысить скорость приложений машинного обучения. Карта также имеет 28 ядер ускорения трассировки лучей.<br><br> NVIDIA объединила 12 ГБ памяти GDDR6 с GeForce RTX 3060, которые подключаются с помощью 192-битного интерфейса памяти. Графический процессор работает на частоте 1320 МГц, которую можно увеличить до 1777 МГц, память работает на частоте 1875 МГц (15 Гбит/с эффективно). Будучи двухслотовой картой, NVIDIA GeForce RTX 3060 получает питание от 1x 12-контактного разъема питания с максимальной потребляемой мощностью 170 Вт.<br><br> Выходы дисплея включают: 1x HDMI 2.1, 3x DisplayPort 1.4a. GeForce RTX 3060 подключается к остальной системе с помощью интерфейса PCI-Express 4.0 x16. Карта имеет длину 242 мм, ширину 112 мм и имеет двухслотовое решение для охлаждения. <br><br>Его цена на момент запуска составляла 1 979,57 беларусских рублей. </p></div><div class="card-image3060GTX"><img src="'+Lr+'" alt=""></div></div>',1);function ns(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",ss,[(0,e._)("div",as,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},cs),is]),ls])):(0,e.kq)("",!0)}var ds={props:{show:Boolean}};const ts=(0,X.Z)(ds,[["render",ns]]);var ms=ts,vs={components:{Modal:ms},data:()=>({show3060Modal:!1})};const ps=(0,X.Z)(vs,[["render",rs]]);var us=ps,gs=s.p+"img/970.bd338431.png";const bs={class:"root"},Gs=(0,e.uE)('<img class="card-image970" src="'+gs+'"><div class="image-overlay image-overlay__primary"><p class="image-title">Информация</p></div><h1 class="card-header">GTX 970</h1><p class="card-text"> GeForce GTX 970 — видеокарта производительного сегмента от NVIDIA, выпущенная 19 сентября 2014 года. </p>',4),hs=[Gs];function ws(o,r,s,a,c,i){const l=(0,e.up)("Modal");return(0,e.wg)(),(0,e.iD)("div",bs,[(0,e._)("div",{class:"main-card",onClick:r[0]||(r[0]=r=>o.show970Modal=!0)},hs),((0,e.wg)(),(0,e.j4)(e.lR,{to:"body"},[(0,e.Wm)(l,{show:o.show970Modal,onClose:r[1]||(r[1]=r=>o.show970Modal=!1)},null,8,["show"])]))])}const Ds={key:0,id:"modal-container"},Is={class:"controls"},xs=(0,e._)("img",{src:u},null,-1),Ts=[xs],Xs=(0,e._)("img",{src:g,class:"nvidia"},null,-1),Ms=(0,e.uE)('<div id="modal-mask"><div class="card-description"><p> GeForce GTX 970 — это видеокарта высокопроизводительного сегмента от NVIDIA, выпущенная 19 сентября 2014 года.<br><br> Созданная на основе 28-нм техпроцесса и основанная на графическом процессоре GM204, в варианте GM204-200-A1 карта поддерживает DirectX 12. Это гарантирует, что все современные игры будут работать на GeForce GTX 970.<br><br> Графический процессор GM204 представляет собой большой чип с площадью кристалла 398 мм² и 5 200 миллионами транзисторов.<br><br> В отличие от полностью разблокированной GeForce GTX 980, которая использует тот же графический процессор, но поддерживает все 2048 шейдеров, NVIDIA отключила некоторые шейдерные блоки на GeForce GTX 970, чтобы достичь целевого количества шейдеров продукта. Он имеет 1664 модуля затенения, 104 модуля наложения текстур и 56 ROP.<br><br> NVIDIA объединила 4 ГБ памяти GDDR5 с GeForce GTX 970, которые подключаются с помощью 256-битного интерфейса памяти. Графический процессор работает на частоте 1050 МГц, которую можно увеличить до 1178 МГц, память работает на частоте 1753 МГц (эффективно 7 Гбит/с). Будучи двухслотовой картой, NVIDIA GeForce GTX 970 питается от двух 6-контактных разъемов питания с максимальной потребляемой мощностью 148 Вт.<br><br> Выходы дисплея включают: 1x DVI, 1x HDMI 2.0, 3x DisplayPort 1.4a. GeForce GTX 970 подключается к остальной системе с помощью интерфейса PCI-Express 3.0 x16. Размеры карты составляют 267 мм x 111 мм x 40 мм, и она имеет двухслотовое решение для охлаждения. <br><br>Его цена на момент запуска составляла 1110,53 беларусских рублей. </p></div><div class="card-image970gtx"><img src="'+gs+'" alt=""></div></div>',1);function _s(o,r,s,a,c,i){return s.show?((0,e.wg)(),(0,e.iD)("div",Ds,[(0,e._)("div",Is,[(0,e._)("button",{class:"modal-close",onClick:r[0]||(r[0]=r=>o.$emit("close"))},Ts),Xs]),Ms])):(0,e.kq)("",!0)}var Fs={props:{show:Boolean}};const ys=(0,X.Z)(Fs,[["render",_s]]);var fs=ys,As={components:{Modal:fs},data:()=>({show970Modal:!1})};const Rs=(0,X.Z)(As,[["render",ws]]);var ks=Rs,Vs={name:"App",components:{gtx1080:f,gtx1070ti:K,rtx2080:vo,gtx1060:Ao,gtx1050:So,gtx770:ur,gtx750:kr,rtx3090:Jr,rtx3060:us,gtx970:ks}};const Ns=(0,X.Z)(Vs,[["render",n]]);var Ps=Ns,Cs=s(907),Es=(0,Cs.MT)({state:{},getters:{},mutations:{},actions:{},modules:{}});(0,a.ri)(Ps).use(Es).mount("#app")}},r={};function s(a){var e=r[a];if(void 0!==e)return e.exports;var c=r[a]={exports:{}};return o[a](c,c.exports,s),c.exports}s.m=o,function(){var o=[];s.O=function(r,a,e,c){if(!a){var i=1/0;for(t=0;t<o.length;t++){a=o[t][0],e=o[t][1],c=o[t][2];for(var l=!0,n=0;n<a.length;n++)(!1&c||i>=c)&&Object.keys(s.O).every((function(o){return s.O[o](a[n])}))?a.splice(n--,1):(l=!1,c<i&&(i=c));if(l){o.splice(t--,1);var d=e();void 0!==d&&(r=d)}}return r}c=c||0;for(var t=o.length;t>0&&o[t-1][2]>c;t--)o[t]=o[t-1];o[t]=[a,e,c]}}(),function(){s.d=function(o,r){for(var a in r)s.o(r,a)&&!s.o(o,a)&&Object.defineProperty(o,a,{enumerable:!0,get:r[a]})}}(),function(){s.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(o){if("object"===typeof window)return window}}()}(),function(){s.o=function(o,r){return Object.prototype.hasOwnProperty.call(o,r)}}(),function(){s.p="/vue-pages/"}(),function(){var o={143:0};s.O.j=function(r){return 0===o[r]};var r=function(r,a){var e,c,i=a[0],l=a[1],n=a[2],d=0;if(i.some((function(r){return 0!==o[r]}))){for(e in l)s.o(l,e)&&(s.m[e]=l[e]);if(n)var t=n(s)}for(r&&r(a);d<i.length;d++)c=i[d],s.o(o,c)&&o[c]&&o[c][0](),o[c]=0;return s.O(t)},a=self["webpackChunkvue_crash_2022"]=self["webpackChunkvue_crash_2022"]||[];a.forEach(r.bind(null,0)),a.push=r.bind(null,a.push.bind(a))}();var a=s.O(void 0,[998],(function(){return s(319)}));a=s.O(a)})();
//# sourceMappingURL=app.08a48064.js.map